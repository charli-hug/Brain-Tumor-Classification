# -*- coding: utf-8 -*-
"""Brain Scan Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Np4qWw6uplPU5dUK-BXnl1vSMYy72IWn
"""

import kagglehub
jillanisofttech_brain_tumor_path = kagglehub.dataset_download('jillanisofttech/brain-tumor')

print('Data source import complete.')

# importing necessary libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier

import kagglehub
dataset_path = kagglehub.dataset_download('jillanisofttech/brain-tumor')

print(f"Dataset downloaded to: {dataset_path}")

import os

print("Files in dataset directory: ")
print(os.listdir(dataset_path))

dataset = pd.read_csv(dataset_path + '/data.csv')

dataset.head()

dataset.tail()

print("\nDataset Info:")
print(dataset.info())

print("\nMissing Values:")
print(dataset.isnull().sum())

# Remove unnecessary columns
if 'Unnamed: 0' in dataset.columns:
    df = dataset.drop('Unnamed: 0', axis=1)

# Split features and target
X = df.iloc[:,:-1].values
y = df.iloc[:,-1].values

# Encode the target variable
le = LabelEncoder()
y = le.fit_transform(y)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scale the features
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

models = {
    'Logistic Regression': LogisticRegression(),
    'KNN': KNeighborsClassifier(n_neighbors=5),
    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),
    'Decision Tree': DecisionTreeClassifier(random_state=42)
}

# Train and evaluate models
results = {}
for name, model in models.items():
    try:
        # Train model
        model.fit(X_train, y_train)

        # Make predictions
        y_pred = model.predict(X_test)

        # Get probabilities for risk assessment
        y_prob = model.predict_proba(X_test)

        # Calculate accuracy
        accuracy = accuracy_score(y_test, y_pred)

        # Store results
        results[name] = {
            'accuracy': accuracy,
            'predictions': y_pred,
            'probabilities': y_prob
        }

        # Print results
        print(f"\n{name} Results:")
        print(f"Accuracy: {accuracy:.4f}")
        print("\nClassification Report:")
        print(classification_report(y_test, y_pred))

        # Plot confusion matrix
        plt.figure(figsize=(8, 6))
        cm = confusion_matrix(y_test, y_pred)
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
        plt.title(f'Confusion Matrix - {name}')
        plt.ylabel('True Label')
        plt.xlabel('Predicted Label')
        plt.show()

    except Exception as e:
        print(f"Error training {name}: {str(e)}")

# Risk Assessment Function
def assess_risk(prediction_probability):
    confidence = max(prediction_probability)

    if confidence >= 0.9:
        return {
            'risk_level': 'High',
            'confidence': confidence,
            'recommendation': 'Immediate specialist review recommended'
        }
    elif confidence >= 0.7:
        return {
            'risk_level': 'Medium',
            'confidence': confidence,
            'recommendation': 'Additional imaging recommended'
        }
    else:
        return {
            'risk_level': 'Low',
            'confidence': confidence,
            'recommendation': 'Routine follow-up'
        }

# Perform risk assessment for best model
best_model_name = max(results, key=lambda k: results[k]['accuracy'])
best_model_probs = results[best_model_name]['probabilities']

print(f"\nRisk Assessment for {best_model_name}:")
risk_assessments = [assess_risk(prob) for prob in best_model_probs]

# Display distribution of risk levels
risk_levels = [assessment['risk_level'] for assessment in risk_assessments]
plt.figure(figsize=(8, 6))
sns.countplot(x=risk_levels)
plt.title('Distribution of Risk Levels')
plt.show()

def predict_new_case(features, model=models[best_model_name], scaler=sc):
    # Scale the features
    scaled_features = scaler.transform([features])

    # Get prediction and probability
    prediction = model.predict(scaled_features)
    probability = model.predict_proba(scaled_features)

    # Get risk assessment
    risk = assess_risk(probability[0])

    return {
        'prediction': prediction[0],
        'risk_assessment': risk
    }